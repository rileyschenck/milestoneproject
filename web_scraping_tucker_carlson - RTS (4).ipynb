{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.foxnews.com/category/shows/tucker-carlson-tonight/transcript\")\n",
    "button = driver.find_element(By.XPATH, \"//div[@class='button load-more js-load-more']\") \n",
    "x = 0\n",
    "for x in range(50):\n",
    "    button.click()    \n",
    "    time.sleep(1)\n",
    "    x+=1\n",
    "    print(x)\n",
    "page_source = driver.page_source # save the source to feed to beautiful soup \n",
    "print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page_source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_soup = soup.find_all('a', href=re.compile('/opinion/.*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = []\n",
    "prefix = 'https://www.foxnews.com/'\n",
    "for link in url_soup: \n",
    "    suffix = re.findall('\\\"\\/(.*?)\\\"', str(link))\n",
    "    if suffix:\n",
    "        url_list.append(prefix + suffix[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list[52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifying for one instance\n",
    "url = url_list[52]\n",
    "#url = 'https://www.foxnews.com/opinion/tucker-carlson-faa-travel-pete-buttigieg'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "title = soup.title.string\n",
    "\n",
    "# #results = soup.find(id='wrapper')\n",
    "# #body = soup.find_all('p')\n",
    "# #text = body[1].text\n",
    "\n",
    "a_tag = soup.find_all('a')\n",
    "for tag in a_tag:\n",
    "    tag.decompose()\n",
    "\n",
    "copy_tag = soup.find_all('p', class_ = \"copyright\")\n",
    "for tag in copy_tag:\n",
    "    tag.decompose()\n",
    "    \n",
    "span_tag = soup.find_all('span')\n",
    "for tag in span_tag:\n",
    "    tag.decompose()\n",
    "    \n",
    "bold_tag = soup.find_all('strong') \n",
    "for tag in bold_tag:\n",
    "    tag.decompose()\n",
    "    \n",
    "italic_tag=soup.find_all('i') \n",
    "for tag in italic_tag:\n",
    "    tag.decompose()\n",
    "\n",
    "other_tag = soup.find_all('p', class_ =\"dek\")\n",
    "for tag in other_tag:\n",
    "    tag.decompose()\n",
    "    \n",
    "other_tag2 = soup.find_all('p', class_ =\"subscribed hide\")\n",
    "for tag in other_tag2:\n",
    "    tag.decompose()\n",
    "    \n",
    "other_tag3 = soup.find_all('p', class_ =\"success hide\") \n",
    "for tag in other_tag3:\n",
    "    tag.decompose()\n",
    "\n",
    "\n",
    "\n",
    "final = soup.find_all('p')\n",
    "# text=''\n",
    "# print(final)\n",
    "finaltext = ''\n",
    "for p in final:\n",
    "\n",
    "    try:\n",
    "        finaltext = finaltext + p.text\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "finaltext\n",
    "# #finaltext = ' '.join(text)\n",
    "# #text\n",
    "# # #soup.find_all('p')\n",
    "# #soup.find('time').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_df = None\n",
    "dfs = []\n",
    "\n",
    "for n, url in enumerate(url_list):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    time = soup.find('time').text\n",
    "    title = soup.title.string\n",
    "\n",
    "    a_tag = soup.find_all('a')\n",
    "    for tag in a_tag:\n",
    "        tag.decompose()\n",
    "\n",
    "    copy_tag = soup.find_all('p', class_ = \"copyright\")\n",
    "    for tag in copy_tag:\n",
    "        tag.decompose()\n",
    "\n",
    "    span_tag = soup.find_all('span')\n",
    "    for tag in span_tag:\n",
    "        tag.decompose()\n",
    "\n",
    "    bold_tag = soup.find_all('strong') \n",
    "    for tag in bold_tag:\n",
    "        tag.decompose()\n",
    "\n",
    "    italic_tag=soup.find_all('i') \n",
    "    for tag in italic_tag:\n",
    "        tag.decompose()\n",
    "\n",
    "    other_tag = soup.find_all('p', class_ =\"dek\")\n",
    "    for tag in other_tag:\n",
    "        tag.decompose()\n",
    "\n",
    "    other_tag2 = soup.find_all('p', class_ =\"subscribed hide\")\n",
    "    for tag in other_tag2:\n",
    "        tag.decompose()\n",
    "\n",
    "    other_tag3 = soup.find_all('p', class_ =\"success hide\") \n",
    "    for tag in other_tag3:\n",
    "        tag.decompose()\n",
    "\n",
    "\n",
    "    final = soup.find_all('p')\n",
    "    # text=''\n",
    "    # print(final)\n",
    "    finaltext = ''\n",
    "    for p in final:\n",
    "\n",
    "        try:\n",
    "            finaltext = finaltext + p.text\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    data={'url': [url],'timestamp': [time], 'title': [title], 'text': [finaltext]}\n",
    "    df = pd.DataFrame(data)\n",
    "    dfs.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat(dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.iloc[19,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_duplicates=full_df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(no_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_duplicates.to_csv('Tucker_transcripts_2.5.23.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
   
