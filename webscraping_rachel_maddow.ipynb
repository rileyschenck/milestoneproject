{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://www.msnbc.com/transcripts/show/rachel-maddow-show', 'https://www.msnbc.com/transcripts/show/rachel-maddow-show?page=2',\n",
    "       'https://www.msnbc.com/transcripts/show/rachel-maddow-show?page=3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--incognito')\n",
    "#options.add_argument(\"start-maximized\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = []\n",
    "transcript_list = []\n",
    "time_list = []\n",
    "\n",
    "for url in urls: \n",
    "    # move to that page, pull the page_source\n",
    "    driver.get(url)\n",
    "    page_source = driver.page_source\n",
    "    \n",
    "    soup = BeautifulSoup(page_source)\n",
    "    url_soup = soup.find_all('a', href=re.compile('.*transcripts.*'))\n",
    "    \n",
    "    \n",
    "    for link in url_soup: \n",
    "        link = str(link.get('href'))\n",
    "        if link == 'https://www.msnbc.com/transcripts':\n",
    "            pass\n",
    "        else:\n",
    "            # store the link\n",
    "            url_list.append(link)\n",
    "            # webscrape the article body with beautiful soup\n",
    "            response = requests.get(link)\n",
    "            soup = BeautifulSoup(response.content)\n",
    "            results=soup.find(id='content')\n",
    "            body=results.find_all('div', class_='article-body__content')\n",
    "            # save the results to the time and transcript lists\n",
    "            transcript_list.append(body[0].text)\n",
    "            time_list.append(soup.find('time').text)\n",
    "            \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(url_list, time_list, transcript_list)), columns =['url', 'timestamp', 'transcript'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Maddow_transcripts.tsv', sep=\"\\t\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
